{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c847df9e-e176-4f50-92de-17373ea90556",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "We already did some hyper-parameter tuning in previous lectures, but we were a little loose about how we did it: (1) we didn't use the validation data like we should have, and (2) we had to write a lot of custom-code to collect the results. If we try a few different models we can get away with being a little sloppy, but now we're going to do things right. You should not be surprised to find out that hyper-parameter tuning being a common ML task, there's functionality in `sklearn` to help us with it. In this assignment, we are going to use it to try different combinations of hyper-parameters for the SVM classifier we trained in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ee9dc6-75c1-421c-8b98-0311e5a80796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb62ea-7268-4b5f-8da4-5f7e196d2444",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60/3791528912.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#we split the data for training and testing and we did the hot encoding and normaliziation as pre processing the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/bank-full.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcat_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#we split the data for training and testing and we did the hot encoding and normaliziation as pre processing the data.\n",
    "bank = pd.read_csv(\"data/bank-full.csv\", sep = \";\")\n",
    "\n",
    "num_cols = bank.select_dtypes(['integer', 'float']).columns\n",
    "cat_cols = bank.select_dtypes(['object']).drop(columns = \"y\").columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bank.drop(columns = \"y\"), bank[\"y\"], \n",
    "                                                    test_size = 0.10, random_state = 42)\n",
    "\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "\n",
    "onehoter = OneHotEncoder(sparse_output= False)\n",
    "onehoter.fit(X_train[cat_cols])\n",
    "onehot_cols = onehoter.get_feature_names_out(cat_cols)\n",
    "X_train_onehot = pd.DataFrame(onehoter.transform(X_train[cat_cols]), columns = onehot_cols)\n",
    "X_test_onehot = pd.DataFrame(onehoter.transform(X_test[cat_cols]), columns = onehot_cols)\n",
    "\n",
    "znormalizer = StandardScaler()\n",
    "znormalizer.fit(X_train[num_cols])\n",
    "X_train_norm = pd.DataFrame(znormalizer.transform(X_train[num_cols]), columns = num_cols)\n",
    "X_test_norm = pd.DataFrame(znormalizer.transform(X_test[num_cols]), columns = num_cols)\n",
    "\n",
    "X_train_featurized = X_train_onehot # add one-hot-encoded columns\n",
    "X_test_featurized = X_test_onehot   # add one-hot-encoded columns\n",
    "X_train_featurized[num_cols] = X_train_norm # add numeric columns\n",
    "X_test_featurized[num_cols] = X_test_norm   # add numeric columns\n",
    "\n",
    "del X_train_norm, X_test_norm, X_train_onehot, X_test_onehot\n",
    "\n",
    "print(\"Featurized training data has {} rows and {} columns.\".format(*X_train_featurized.shape))\n",
    "print(\"Featurized test data has {} rows and {} columns.\".format(*X_test_featurized.shape))\n",
    "\n",
    "X_train_featurized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa26e8-14d2-4089-ade8-2940658105d3",
   "metadata": {},
   "source": [
    "There are three main ways to search the **hyper-parameter space**:\n",
    "\n",
    "- **Grid search:** tries every combination of hyper-parameters\n",
    "- **Random search:** tries a random subset of all combinations of hyper-parameters\n",
    "- **Bayesian optimization:** tries a subset of all combinations of hyper-parameters (like random search) but does so in a more intelligent way, based on trading off the need to **explore** (trying a part of the hyper-parameter space thus far unexplored) and the need to **exploit** (focusing on a part of the hyper-parameter space that thus far seems promising)\n",
    "\n",
    "We will use a grid search algorithm here, as implemented by the `GridSearchCV` function. As a bonus, the grid search algorithm uses cross-validation (CV) to evaluate the model. Cross-validation can slow down the process, but we can use a lower number of **folds** to speed it up.\n",
    "\n",
    "SVMs have two important **high-level hyper-parameters** and then some lower-level ones that depend on the high-level ones. The high-level hyper-parameters are `C`, `kernel`. Depending on the choice of `kernel`, we can also specify `degree` and `gamma`. You can read more about that [here](https://scikit-learn.org/stable/modules/svm.html#kernel-functions).\n",
    "\n",
    "In addition to the hyper-parameters mentioned above, `SVC` also has some important arguments such as `max_iter` and `class_weight`, or `cache_size` which we should be aware of.\n",
    "\n",
    "- Use `GridSearchCV` to train multiple `SVC` classifiers with different hyper-parameter combinations. <span style=\"color:red\" float:right>[20 point]</span>\n",
    "  - The hyper-parameters you want to try are `kernel`, `degree`, `C` and `gamma`. You should pick two or three different choices for each. \n",
    "  - For `SVC` setting `probability = True` slows down training considerably, so it's not a good idea to use it during grid search. (Instead, we can retrain the final model using the hyper-parameters combinations that we found and set `probability = True` to if we need to get soft predictions but we won't worry about that here.) \n",
    "  - We leave it to you to read the documentation for `SVC` to see what choices make sense. Moreover, your grid search should perform 5-fold cross-validation to select the best model.\n",
    "  - It's best to avoid running everything in one line. So try to break your code into a few different steps to make it easy to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63cfda19-d63b-4804-806b-99f7a790c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we defined our  SVC model and we assigned 2 to degree for the kernel trick.\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "model=SVC(degree=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1ac688f-e988-4a43-abf3-d3fe1cee4ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d356d9-eb21-401e-aaa4-58637e4e03aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we defined the hyperparameters for our modeling. we chose two values for c and gammad and two function for kernel tricks.\n",
    "param_grid={'C':[0.1, 1],'gamma':[1, 0.1],'kernel':['rbf','poly']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959979e0-59e3-4de1-a199-3def6b5b3e94",
   "metadata": {},
   "source": [
    "- Run your grid search to train all the models. (Later, we will see how to pick the model with the best combination of hyper-parameters: in this context, hyper-parameter tuning is often also referred to as **model selection**.)  <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c93bffe7-2b21-40b1-afd6-d9790db1fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we defined our object for doing the GridSearchCV to find the the best hyperparameter and also the best estimator.\n",
    "grid = GridSearchCV(model, param_grid, refit = True, verbose = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af62954a-7758-4fc2-b797-a973788144f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.884 total time= 3.6min\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.884 total time= 3.7min\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.884 total time= 3.6min\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.884 total time= 3.5min\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.884 total time= 4.0min\n",
      "[CV 1/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.903 total time= 1.7min\n",
      "[CV 2/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.906 total time= 1.7min\n",
      "[CV 3/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.904 total time= 1.6min\n",
      "[CV 4/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.904 total time= 1.7min\n",
      "[CV 5/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.905 total time= 1.7min\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.898 total time=  34.4s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.898 total time=  32.8s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.901 total time=  35.9s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.896 total time=  34.6s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.898 total time=  32.4s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.898 total time=  24.9s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.901 total time=  24.4s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.901 total time=  25.4s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.896 total time=  28.4s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.896 total time=  27.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.886 total time= 4.1min\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.884 total time= 4.0min\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.885 total time= 4.3min\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.884 total time= 4.4min\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.884 total time= 4.4min\n",
      "[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.904 total time=13.2min\n",
      "[CV 2/5] END .........C=1, gamma=1, kernel=poly;, score=0.904 total time=13.3min\n",
      "[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=0.904 total time=12.4min\n",
      "[CV 4/5] END .........C=1, gamma=1, kernel=poly;, score=0.904 total time=12.1min\n",
      "[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=0.904 total time=13.4min\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.906 total time=  38.4s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.904 total time=  36.2s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.906 total time=  36.3s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.905 total time=  40.6s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.908 total time=  35.9s\n",
      "[CV 1/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.903 total time=  29.4s\n",
      "[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.906 total time=  32.4s\n",
      "[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.904 total time=  30.3s\n",
      "[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.900 total time=  31.4s\n",
      "[CV 5/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.904 total time=  32.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(degree=2),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1], &#x27;gamma&#x27;: [1, 0.1],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(degree=2),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1], &#x27;gamma&#x27;: [1, 0.1],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(degree=2)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(degree=2)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(degree=2),\n",
       "             param_grid={'C': [0.1, 1], 'gamma': [1, 0.1],\n",
       "                         'kernel': ['rbf', 'poly']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_featurized, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a14cf829-6ca2-4b00-9084-62122afa4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on our modeling.we run the fitting 40 times based on the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4492621d-eb56-4d75-9321-b62795abc978",
   "metadata": {},
   "source": [
    "All the results generated from the work done by the grid search is stored in the `cv_results_` attribute. For example, if we want to know the combination of hyper-parameters that was tried in the 10th iteration, we can run `clf.cv_results_['params'][9]` (assuming the trained model is called `clf`) and if we want to know the cross-validated evaluation score for that 10th iteration, we can run `clf.cv_results_['mean_test_score'][9]`.\n",
    "\n",
    "Note that we need to be careful about terminology here. Unfortunately, the hyper-parameters are called `params` by `GridSearchCV`. But in ML **parameters** are the things that the algorithm learns from the data (such as the coefficients in the prediction equation), whereas **hyper-parameters** cannot be learned from the data, which is why we have to tune them by trying different combinations. Also, the cross-validated score is called `mean_test_score` even though we are not using the test data to evaluate it. At least not during model selection. We will use the test data later to evaluate the final model.\n",
    "\n",
    "Time to pull the best model. We can explicitly call the `clf.best_estimator_` method. However, calling `clf.best_estimator_` explicitly is not necessary: by calling `clf.estimator` it is **implied** that we are calling the best estimator. This means that if we call `clf.predict`, we would be using the best estimator to get predictions.\n",
    "\n",
    "- Get predictions on the training and test data for the best model. Finally, get the precision and recall of the best estimator to see how they compare to what we got from logistic regression during the lecture. <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4c5425f-4af0-4f75-89cd-1ed37e5d74b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "#here we found the best hyperparameter for our modeling.\n",
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1002cc3-33b9-404b-a471-f60675438615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the best estimator is found with grid.best_estimator_ . we can use it for model prediction.\n",
    "best_model=grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a79a2e2d-b5e6-4589-ac36-898da311f623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, degree=2, gamma=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, degree=2, gamma=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, degree=2, gamma=0.1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e1f0bcc-12c9-4b2e-a0e1-e9217d459418",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train=best_model.predict(X_train_featurized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37be7ead-e7bc-4949-a8fb-92d363706970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.93      0.98      0.96     35954\n",
      "         yes       0.78      0.46      0.58      4735\n",
      "\n",
      "    accuracy                           0.92     40689\n",
      "   macro avg       0.86      0.72      0.77     40689\n",
      "weighted avg       0.91      0.92      0.91     40689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#after prediction,we can see the results of our modeling. and we can see that there is an improvement in the prediction of traing set.\n",
    "print(classification_report(y_train, predict_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335fec04-0182-4347-b5b0-d3ea583ebdf3",
   "metadata": {},
   "source": [
    "predict_test=best_model.predict(X_test_featurized)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "babc9d38-e3d8-4e16-a409-d5bac7806929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.92      0.97      0.95      3968\n",
      "         yes       0.67      0.39      0.49       554\n",
      "\n",
      "    accuracy                           0.90      4522\n",
      "   macro avg       0.79      0.68      0.72      4522\n",
      "weighted avg       0.89      0.90      0.89      4522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#after prediction,we can see the results of our modeling.\n",
    "#and we can see that there is not much improvement in predicting  the testing set comparing to the traing set and the result of the logistic regrssion accuracy.\n",
    "\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b71cb-bb96-4aeb-b44b-57246120249e",
   "metadata": {},
   "source": [
    "The results of the logistic regression for traing and testing set are:\n",
    "Precision = 65% and recall = 35% on the training data.\n",
    "Precision = 63% and recall = 34% on the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae3fa0-8bb0-4c07-bb1c-75df39c835e5",
   "metadata": {},
   "source": [
    "When we compared our results with the logistic regression used in the lecture, we have an improvement in the prediction of the traing set.\n",
    "but there is not much diffrent in the accuracy of testing set between two models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091e9345-b470-4945-85d3-8ef2905c400d",
   "metadata": {},
   "source": [
    "# End of assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
